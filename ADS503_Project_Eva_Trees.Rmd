---
title: "ADS503_Project_Eva"
author: "Eva Chow"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries
## REMOVE NOTE LATER - ggplot and dplyr are part of tidyverse, so removed them. 
```{r message=FALSE, warning=FALSE}
library(haven)
library(caret)
library(gridExtra)
library(corrplot)
library(e1071)
library(car)
library(lattice)
library(doParallel)
library(RANN)
library(rpart)
library(party)
library(partykit)
library(tidyverse)
library(rpart.plot)
library(randomForest)
library(RWeka)
library(gbm)
library(Cubist)
```

# Set up Parallelization - Note, you can reduce number of clusters if needed not sure if R does it automatically if you set over the number of cores on your CPU
```{r}
cl <- makeCluster(6)
registerDoParallel(cl)
```


# Read in data
```{r}
Demographic <- read_xpt("P_DEMO.XPT")
BodySize <- read_xpt("P_BMX.XPT")
Chol_ldl <- read_xpt("P_TRIGLY.XPT")
```

# Create Dataset
Chol-ldl
```{r}
#Select Variables of interest
Chol_ldl <- Chol_ldl %>% select(SEQN, LBDLDL)
#NA in target feature won't be useful
Chol_ldl <- Chol_ldl %>% drop_na()
```

Demographic
```{r}
#Get rid of variables we don't need
Drop_col <- c('SDDSRVYR', 'RIDSTATR', 'RIDEXMON', 'SIAPROXY', 'SIAINTRP', 'FIAPROXY', 'FIAINTRP', 'MIAPROXY', 'MIAINTRP', 'WTINTPRP', 'WTMECPRP', 'SDMVPSU', 'SDMVSTRA')
Demographic <- Demographic %>% select(-one_of(Drop_col))
```

BodySize
```{r}
Drop_col <- c('BMIWT', 'BMIRECUM', 'BMIHEAD', 'BMIHT', 'BMILEG', 'BMIARML', 'BMIARMC', 'BMIWAIST', 'BMIHIP', 'BMDSTATS')
BodySize <- BodySize %>% select(-one_of(Drop_col))
```

Join
```{r}
J1 <- Chol_ldl %>% left_join(Demographic, by = "SEQN")
Chol <- J1 %>% left_join(BodySize, by = "SEQN")
Chol <- Chol %>% select(!SEQN)
```

# Cleaning
## Changing factors for EDA 
## Changing Variables to the Correct Type 
```{r}
Chol_2 <- Chol
factors <- c("RIAGENDR", "RIDRETH1", "RIDRETH3", "DMDBORN4", "DMDEDUC2", "DMDMARTZ", "RIDEXPRG", "SIALANG", "FIALANG", "MIALANG", "AIALANGA")
Chol_2[,factors] <- lapply(Chol_2[,factors], factor)
```

## Change factor levels to be more interpretable
```{r}
levels(Chol_2$RIAGENDR) <- c("Male", "Female")
levels(Chol_2$RIDRETH1) <- c("Mex", "OHis", "White", "Black", "Oth")
levels(Chol_2$RIDRETH3) <- c("Mex", "OHis", "White", "Black", "Asian", "Oth")
levels(Chol_2$DMDBORN4) <- c("USA", "Oth", "Ref", "DK")
levels(Chol_2$DMDYRUSZ) <- c("<5", "5-15", "15-30", ">30", "Ref", "DK")
levels(Chol_2$DMDEDUC2) <- c("<9", "9-11", "HS", "AA", "BS+", "Ref", "DK")
levels(Chol_2$DMDMARTZ) <- c("Mar", "Sep", "Nev", "Ref", "DK")
levels(Chol_2$RIDEXPRG) <- c("Yes", "No", "DK")
levels(Chol_2$SIALANG) <- c("English", "Spanish")
levels(Chol_2$FIALANG) <- c("English", "Spanish")
levels(Chol_2$MIALANG) <- c("English", "Spanish")
levels(Chol_2$AIALANGA) <- c("English", "Spanish", "Asian")
```


# EDA
## NAs
### By Variable - Removed variables with over 3000 observations missing
```{r message=FALSE, warning=FALSE}
Variable_na <- Chol_2 %>% select(everything()) %>% summarise_all(funs(sum(is.na(.)))) %>% pivot_longer(cols = c(colnames(Chol_2[,1:ncol(Chol_2)])), names_to = "Variable", values_to = "Missing") %>% arrange(desc(Missing))
Drop_col <- c("RIDAGEMN", "BMXRECUM", "BMXHEAD", "BMDBMIC", "RIDEXPRG", "DMDYRUSZ")
Chol_2 <- Chol_2 %>% select(-one_of(Drop_col))
```

### By Row
```{r}
row_na <- rowSums(is.na(Chol_2))
row_na <- data.frame(row_na, Row = c(1:length(row_na)))
row_na <- row_na %>% arrange(desc(row_na))
#Most missing values in a row is 12, not bad
```

## Distributions
### Response - LDL Cholesterol
```{r}
#Looks like a fairly normal distribution, maybe a little skewed to the right. 
ggplot(Chol_2, aes(x = LBDLDL)) + geom_histogram() + ggtitle("LDL Distribution Histogram")
skewness(Chol_2$LBDLDL)
#skewness value .7886403 confirms very mild skewness to the right
```

### Predictors
Factors
```{r}
Chol_fact <- Chol_2 %>% select_if(is.factor)
Chol.bar <- function(xvar){
  ggplot(Chol_fact, aes_(x = as.name(xvar))) +
    geom_bar(color = "black") + coord_flip()
}
Lang_barplots <- lapply(names(Chol_fact[,7:10]), Chol.bar)
Oth_barplots <- lapply(names(Chol_fact[,1:6]), Chol.bar)
grid.arrange(grobs = Lang_barplots, top = "Language Features")
grid.arrange(grobs = Oth_barplots, top = "Other Demographics")
```

Numeric
```{r message=FALSE, warning=FALSE}
Chol_num <- Chol_2 %>% select_if(is.numeric) %>% select(!LBDLDL)
Chol.hist <- function(xvar){
  ggplot(Chol_num, aes_(x = as.name(xvar))) +
    geom_histogram(color = "black") 
}
Dem_hist <- lapply(names(Chol_num[,1:2]), Chol.hist)
Body_hist <- lapply(names(Chol_num[,3:10]), Chol.hist)
grid.arrange(grobs = Dem_hist, top = "Demographic Features")
grid.arrange(grobs = Body_hist, top = "Body Measures")
```

## Correlations
Heatmap
```{r}
Chol_dummy <- fastDummies::dummy_cols(Chol_2)
Chol_dummy <- Chol_dummy %>% select_if(~!is.factor(.))
Chol_dummy[] <- lapply(Chol_dummy, as.numeric)
Chol_cor <- cor(Chol_dummy, use = "complete.obs")
Chol_corplot <- corrplot(cor(Chol_dummy, use = "complete.obs"), tl.pos = 'n')
#Looks like some dummy variables that are refusal could be messing up correlations
Drop_col <- c("DMDBORN4_Ref", "DMDBORN4_DK", "DMDEDUC2_Ref", "DMDEDUC2_DK", "DMDEDUC2_NA", "DMDMARTZ_Ref", "DMDMARTZ_NA", "FIALANG_NA", "MIALANG_NA", "AIALANGA_NA")
Chol_dummy_2 <- Chol_dummy %>% select(-one_of(Drop_col))
cor(Chol_dummy_2, use = "complete.obs")
corrplot(cor(Chol_dummy_2, use = "complete.obs"), tl.pos = 'n', type = 'lower')
```
```{r}
# Mini Correlations: Sociological Measures:
socio <- Chol_dummy_2[,c("RIAGENDR_Male","RIAGENDR_Female",
                       "RIDRETH1_Mex", "RIDRETH1_OHis", "RIDRETH1_White", 
                       "RIDRETH1_Black", "RIDRETH1_Oth", "RIDRETH3_Mex", "RIDRETH3_OHis",
                       "RIDRETH3_White", "RIDRETH3_Black", "RIDRETH3_Asian", "RIDRETH3_Oth",
                       "DMDBORN4_USA", "DMDBORN4_Oth", "DMDEDUC2_<9", "DMDEDUC2_9-11",
                       "DMDEDUC2_HS", "DMDEDUC2_AA", "DMDEDUC2_BS+","DMDMARTZ_Mar",
                       "DMDMARTZ_Sep", "DMDMARTZ_Nev", "DMDMARTZ_DK", "SIALANG_English", 
                       "SIALANG_Spanish", "FIALANG_English", "FIALANG_Spanish",
                       "MIALANG_English","MIALANG_Spanish", "AIALANGA_English",
                       "AIALANGA_Spanish", "AIALANGA_Asian", "LBDLDL")]

cor(socio, use = "complete.obs")
corrplot(cor(socio, use = "complete.obs"), tl.pos = 'y', type = 'lower', 
         order = "hclust", tl.cex = 0.5)
```
```{r}
# Mini Correlations: Biological Measures:
biologic <- Chol_dummy_2[,c("RIDAGEYR", "BMXWT", "BMXHT", "BMXBMI", 
                            "BMXLEG", "BMXARML", "BMXARMC", "BMXWAIST",
                            "BMXHIP", "RIAGENDR_Male", "RIAGENDR_Female","LBDLDL")]
cor(biologic, use = "complete.obs")
corrplot(cor(biologic, use = "complete.obs"), tl.pos = 'y', type = 'lower', 
         order = "hclust", tl.cex = 0.8)
# correlations between certain biological measures make sense. BMI is derived from the MASS and height of an individual, so it makes sense that many of the BMI measurements correlate with each other. (i.e. hip, waist, and weight measurements correlate with a higher BMI. Being female correlates negatively with leg and arm length as well as height)
```

# REMOVE NOTE LATER - MAY NEED TO USE DUMMY CHOL DATA FOR HIGH CORRELATIONS - REGULAR CHOL STILL HAS CATEGORICAL VARIABLES AS SINGLE NUMERIC VARIABLES.
```{r}
# let's check for highly correlated predictors
# we'll do this on our non factor transformed dataset
dim(Chol)

# 27 variables. let's find correlations greater than 0.80 and see how the data looks if removed
corr_Chol <- cor(Chol)

# if removed, how many variables are left
high_corr_Chol <- findCorrelation(corr_Chol, cutoff = 0.80)
no_corr_Chol <- Chol[, -high_corr_Chol]
dim(no_corr_Chol)
```
# Checking things above with Dummy Variable Data
## CURRENTLY TESTING STUFF HERE FOR HOW TO DEAL WITH DUMMY DATA WITH COR
```{r}
testdata <- Chol_dummy
testdata <- apply(Chol_dummy, 2, function(y) {y[!is.finite(y)] = NA; y})
testdata <- testdata[complete.cases(testdata), ]
testdata <- testdata[, -nearZeroVar(testdata)]
testdata <- data.frame(testdata)
dim(Chol_dummy)
Cor_chol_dummy <- cor(testdata)
high_corr_dummy <- findCorrelation(Cor_chol_dummy, cutoff = 0.8)
```

```{r}
# looking at a base linear model, to see significant variables 
model0 <- lm(LBDLDL~., Chol_2)
summary(model0)
  # significant contributors: variable (Pr(>|t|)) 
    # RIDAGEYR (0.000132)
    # (Intercept) (0.043474)
    # MDBORN4Oth (0.076414) 
    # AIALANGASpanish (0.041803)
    # BMXLEG (0.033051)
    # BMXARMC (0.004507) 
    # BMXWAIST (0.071888)
```

```{r}
# looking at VIF for baseline linear:
vif(model0)
  # highly/perfectly correlated factors, we might need to drop some
```

# Degenerate Predictors
```{r}
# Let's check for degenerate predictors from the original dataset
nearZeroVar(Chol, saveMetrics = FALSE)
deg_chol <- subset(Chol, select=c(4,11,16,18,19))
colnames(deg_chol)

# Do it again on factor dataset
nearZeroVar(Chol_2, saveMetrics = FALSE)
deg_chol2 <- subset(Chol_2, select=c(13))
colnames(deg_chol2)

# we may have to consider removing depending on the data used for modeling
```



# Splitting
## NOTE SWITCHED TRAINING TO DUMMY
```{r}
# set the seed and split the data. We'll do an 80/20 split
set.seed(123)
Chol_split <- createDataPartition(Chol$LBDLDL, p=0.80, list=FALSE)

# split into train and test
Chol_train <- Chol_dummy[Chol_split,]
Chol_test <- Chol_dummy[-Chol_split,]

# split predictors from the target
Chol_train_X <- as.data.frame(subset(Chol_train, select=-c(LBDLDL))) 
Chol_train_y <- Chol_train$LBDLDL

Chol_test_X <- as.data.frame(subset(Chol_test, select=-c(LBDLDL)))
Chol_test_y <- Chol_test$LBDLDL

# Creating imputed data sets
Chol_imp <- preProcess(Chol_train_X, method = c("center", "scale", "knnImpute"))
Chol_train_X_imp <- predict(Chol_imp, Chol_train_X)
Chol_test_X_imp <- predict(Chol_imp, Chol_test_X)

# Adding Resampling/Validation Set and Control 
set.seed(123)
Chol_folds <- createFolds(y = Chol_train_X, k = 10, returnTrain = T)
Chol_control <- trainControl(method = "cv", index = Chol_folds)
```

## Numeric training data set with just the numeric variables and gender (Just going off a hunch that having too many dummy variables is hurting linear model performance).
```{r}
Drop_col <- c('RIDRETH1', 'RIDRETH3', 'DMDBORN4', 'DMDEDUC2', 'DMDMARTZ', 'SIALANG', 'FIALANG', 'MIALANG', 'AIALANGA', 'LBDLDL')
Chol_num <- Chol_2 %>% select(-one_of(Drop_col))

Chol_num_tr_X <- as.data.frame(Chol_num[Chol_split, ])
Chol_num_test_X <- as.data.frame(Chol_num[Chol_split, ])

#Preprocess
Chol_imp <- preProcess(Chol_num_tr_X, method = c("center", "scale", "knnImpute"))
Chol_num_tr_X <- predict(Chol_imp, Chol_num_tr_X)
Chol_num_test_X <- predict(Chol_imp, Chol_num_test_X)

# Adding Resampling/Validation Set and Control 
set.seed(123)
Chol_folds_num <- createFolds(y = Chol_num_tr_X, k = 10, returnTrain = T)
Chol_control_num <- trainControl(method = "cv", index = Chol_folds_num)
```


# Linear Models - Hunter
## OLS 
### Create Initial Model
```{r}
Chol_ols_tune <- train(x = Chol_train_X_imp, y = Chol_train_y, method = "lm", trControl = Chol_control)
plot(Chol_ols_tune$finalModel)
```
### FIX TRAINING SET
```{r}
# VIF shows aliased coefficients, need to get rid of those by removing high cor predictors
test <- cor(Chol_train_X_imp)
# Also have an issue with DMDEDUC2_DK all being zero so get rid of high var predictors
Chol_tr_x_imp_vr <- Chol_train_X_imp[, -nearZeroVar(Chol_train_X_imp)]
Chol_tr_X_imp_fin <- Chol_tr_x_imp_vr[, -findCorrelation(cor(Chol_tr_x_imp_vr), cutoff = 0.9)] 
```

### Tune Another Model
```{r}
Chol_ols_tune2 <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "lm", trControl = Chol_control)
plot(Chol_ols_tune2$finalModel)
summary(Chol_ols_tune2$finalModel)
```

### Tune model with BoxCox to see if it will help normality issues - Didn't do much, we'll just stick with the non-transformed data
```{r}
Chol_bct <- preProcess(Chol_tr_X_imp_fin, method = "BoxCox")
Chol_tr_boxcox <- predict(Chol_bct, Chol_tr_X_imp_fin)

Chol_ols_tune3 <- train(x = Chol_tr_boxcox, y = Chol_train_y, method = "lm", trControl = Chol_control)
plot(Chol_ols_tune3$finalModel)
summary(Chol_ols_tune3$finalModel)
```

### Try reduced data - Didn't really help our diagnostic plot, so we'll go with the regular dummy data
```{r}
Chol_ols_tune_num <- train(x = Chol_num_tr_X, y = Chol_train_y, method = "lm", trControl = Chol_control_num, preProc = "BoxCox")
plot(Chol_ols_tune_num$finalModel)
summary(Chol_ols_tune_num$finalModel)
```

### Final OLS Model
```{r}
Chol_sig_tr <- Chol_tr_X_imp_fin %>% select(RIDAGEYR, BMXHT, BMXBMI, BMXLEG, BMXARMC,  DMDBORN4_Oth, DMDEDUC2_NA, MIALANG_NA, AIALANGA_NA)
Chol_ols <- train(x = Chol_sig_tr, y = Chol_train_y, method = "lm", trControl = Chol_control)
plot(Chol_ols$finalModel)
summary(Chol_ols$finalModel)

#Predict on test data
Chol_ols_res <- predict(Chol_ols, Chol_test_X)
```

## PCR and PLS
### PCR
```{r}
set.seed(123)
Chol_pcr <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "pcr", tuneGrid = expand.grid(ncomp=1:32), trControl = Chol_control)
Chol_pcr

set.seed(123)
Chol_pcr_box <- train(x = Chol_tr_boxcox, y = Chol_train_y, method = "pcr", tuneGrid = expand.grid(ncomp=1:32), trControl = Chol_control)
Chol_pcr_box

set.seed(123)
Chol_pcr_num <- train(x = Chol_num_tr_X, y = Chol_train_y, method = "pcr", tuneGrid = expand.grid(ncomp=1:8), trControl = Chol_control_num)
Chol_pcr_num

pcr_resamp <- Chol_pcr$results
pcr_resamp$Model <- "PCR"

box_pcr_resamp <- Chol_pcr_box$results
box_pcr_resamp$Model <- "BPCR"

num_pcr_resamp <- Chol_pcr_num$results
num_pcr_resamp$Model <- "PCR"
```

### PLS
```{r}
set.seed(123)
Chol_pls <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "pls", tuneGrid = expand.grid(ncomp = 1:32), trControl = Chol_control)
Chol_pls

set.seed(123)
Chol_pls_box <- train(x = Chol_tr_boxcox, y = Chol_train_y, method = "pls", tuneGrid = expand.grid(ncomp = 1:32), trControl = Chol_control)
Chol_pls_box

set.seed(123)
Chol_pls_num <- train(x = Chol_num_tr_X, y = Chol_train_y, method = "pls", tuneGrid = expand.grid(ncomp = 1:8), trControl = Chol_control_num)
Chol_pls_num

pls_resamp <- Chol_pls$results
pls_resamp$Model <- "PLS"

pls_box_resamp <- Chol_pls_box$results
pls_box_resamp$Model <- "BPLS"

pls_num_resamp <- Chol_pls_num$results
pls_num_resamp$Model <- "PLS"
```

### Compare

```{r}
plot_data <- rbind(pcr_resamp, box_pcr_resamp, pls_resamp, pls_box_resamp)
xyplot(RMSE ~ ncomp, data = plot_data, xlab = "# of Components", ylab = "RMSE (Cross-validation)", auto.key = list(columns = 4), groups = Model, type = c("o", "g"))

plot2_data <- rbind(num_pcr_resamp, pls_num_resamp)
xyplot(RMSE ~ ncomp, data = plot2_data, xlab = "# of Components", ylab = "RMSE (Cross-validation)", auto.key = list(columns = 2), groups = Model, type = c("o", "g"))
```

## Penalized Models
### Ridge
```{r}
set.seed(123)
Chol_ridge <- train(x = Chol_tr_X_imp_fin, y= Chol_train_y, method = "ridge", tuneGrid = expand.grid(lambda = seq(0, .1, length = 15)), trControl = Chol_control)
Chol_ridge

set.seed(123)
Chol_ridge_box <- train(x = Chol_tr_boxcox, y= Chol_train_y, method = "ridge", tuneGrid = expand.grid(lambda = seq(0, .1, length = 15)), trControl = Chol_control)
Chol_ridge_box

set.seed(123)
#Chol_ridge_num <- train(x = Chol_num_tr_X, y= Chol_train_y, method = "ridge",  trControl = Chol_control_n)
#Chol_ridge_num

print(update(plot(Chol_ridge), xlab = "Penalty"))
print(update(plot(Chol_ridge_box), xlab = "Penalty"))
```

### Elastic Net - having trouble getting numeric data to run through it
```{r}
enet_grid <- expand.grid(lambda = c(0, 0.01, 0.1), fraction = seq(0.05, 1, length = 20))

Chol_enet <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "enet", tuneGrid = enet_grid, trControl = Chol_control)
Chol_enet

Chol_enet_box <- train(x = Chol_tr_boxcox, y = Chol_train_y, method = "enet", tuneGrid = enet_grid, trControl = Chol_control)
Chol_enet_box

#Chol_enet_num <- train(x = as.matrix(Chol_tr_X_imp_fin), y = Chol_train_y, method = "enet", tuneGrid = enet_grid, trControl = Chol_control_num)

plot(Chol_enet)
plot(Chol_enet_box)
```

# Regression Trees - Eva
## Single Regression Trees
### Tree with CART based splits (rpart) and optimization with default parameters
```{r message=FALSE, warning=FALSE}
set.seed(123)
# let's see how it splits the training data
Chol_rpart <- rpart(Chol_train_y ~., data = Chol_tr_X_imp_fin, cp = 0.003)

summary(Chol_rpart)
rpart.plot(Chol_rpart)

# tune and predict
Chol_rpart_tune <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "rpart", cp = 0.003)
Chol_rpart_pred <- predict(Chol_rpart_tune, Chol_test_X_imp)
postResample(pred = Chol_rpart_pred, obs = Chol_test_y)
# Rsquared value of 0.066 isn't too great. RMSE of 33.0. Let's compare to other trees
```
### Tree with CART based splits (rpart2 to tune over max depth)
```{r}
set.seed(123)
Chol_rpart2_tune <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "rpart2", cp = 0.003)
Chol_rpart2_pred <- predict(Chol_rpart2_tune, Chol_test_X_imp)
postResample(pred = Chol_rpart2_pred, obs = Chol_test_y)
# minor improvement? Rsquared value of 0.071 and RMSE of 32.9
```


## Bagged Trees
```{r}
set.seed(123)
Chol_bagtree <- train(x=Chol_tr_X_imp_fin, y = Chol_train_y, method = "treebag", nbagg = 70, trControl = Chol_control)
Chol_bagtree
# Rsquared value of 0.033. RMSE is 35.3. Still not fantastic
```

## Random Forest
```{r}
set.seed(123)

rfmtryValues <- seq(1,10,1)

Chol_rf <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "rf", ntree = 300, tuneGrid = data.frame(mtry=rfmtryValues), trControl=Chol_control) # 300 trees provides the highest Rsquared value when checking with test data
Chol_rf
plot(Chol_rf)

Chol_rf_pred <- predict(Chol_rf, Chol_test_X_imp)
postResample(pred = Chol_rf_pred, obs = Chol_test_y)
# Rsquared value of 0.077. RMSE of 33.1
```

## Boosted Trees
```{r}
# some control parameters
gbmGrid <- expand.grid(interaction.depth = c(1,3,5,7,9), n.trees=300, shrinkage = c(0.01, 0.1), n.minobsinnode=5)

set.seed(123)
Chol_gbm <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "gbm", tuneGrid = gbmGrid, verbose = FALSE, trControl = Chol_control)
Chol_gbm

Chol_gbm_pred <- predict(Chol_gbm, Chol_test_X_imp)
postResample(pred = Chol_gbm_pred, obs = Chol_test_y)
# RMSE 32.9 and Rsquared 0.081
```

## Model Trees
### Model Trees (M5)
```{r message=FALSE, warning=FALSE}
# decision tree with linear regression at terminal nodes to predict continuous variables
set.seed(123)
Chol_M5 <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "M5", trControl = Chol_control, control = Weka_control(M=10))

plot(Chol_M5)

Chol_M5_pred <- predict(Chol_M5, Chol_test_X_imp)
postResample(pred = Chol_M5_pred, obs = Chol_test_y)
# Rsquared value of 0.076 and RMSE of 33.6
```

### Model Tree (Rule Based M5)
```{r message=FALSE, warning=FALSE}
# decision tree with linear regression at terminal nodes to predict continuous variables
set.seed(123)
Chol_M5rules <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "M5Rules", trControl = Chol_control, control = Weka_control(M=10))

plot(Chol_M5rules)

Chol_M5rules_pred <- predict(Chol_M5rules, Chol_test_X_imp)
postResample(pred = Chol_M5rules_pred, obs = Chol_test_y)
# Slight improvement, Rsquared value of 0.087 and RMSE of 32.8
```

## Cubist
```{r}
set.seed(123)
Chol_cube <- train(x = Chol_tr_X_imp_fin, y = Chol_train_y, method = "cubist", trControl = Chol_control)

plot(Chol_cube)

Chol_cube_pred <- predict(Chol_cube, Chol_test_X_imp)
postResample(pred = Chol_cube_pred, obs = Chol_test_y)
# "Best performing" so far, but ever so slightly over the other models. Rsquared of 0.092 and RMSE of 32.6
```

